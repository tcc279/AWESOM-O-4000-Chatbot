{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import re\n",
    "import pickle\n",
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open previous lines text\n",
    "f=open('previous.txt','r',errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing bad_chars_list \n",
    "bad_chars = ['\\n'] \n",
    "for i in bad_chars : \n",
    "    raw = raw.replace(i, ' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing bad_chars_list number 2 \n",
    "bad_chars = ['\\''] \n",
    "for i in bad_chars : \n",
    "    raw = raw.replace(i, \"'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jone/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jone/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization functions\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if user inputs standard greetings the chatbot will output the following\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"how's it going?\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open convo.pickle dictionary with {previous line:Cartman's line that follows}\n",
    "with open('convo.pickle', 'rb') as handle:\n",
    "    convo_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns Cartman's lines that follow the previous line \n",
    "#with the least cosine distance from the user input\n",
    "#if the user input line is not similar to any of the previous line\n",
    "#chatbot will output that it does not understand\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english', ngram_range=(1,2))\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf == 0):\n",
    "        robo_response=robo_response+\"AWESOM-O does not understand\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        for i in convo_dict:\n",
    "            if sent_tokens[idx] in i:\n",
    "                response = convo_dict[i]\n",
    "            else:\n",
    "                continue\n",
    "        robo_response = robo_response+response \n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional cleaning function\n",
    "def replace_value_with_definition(key_to_find, definition):\n",
    "    for key in convo_dict.keys():\n",
    "        if key == key_to_find:\n",
    "            convo_dict[key] = definition\n",
    "\n",
    "replace_value_with_definition('what do you think happens if you do have it?',            \n",
    "                              'they drag you out of here, put you in this big containment facility, where they stick a cold metal pipe up your *** with this clear jelly, and then they shock your *****. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWESOM-O: Greetings. I am the AWESOM-O 4000. AWESOM-O is here to answer your questions. Type \"shut down\" to end conversation\n",
      "hi\n",
      "AWESOM-O: *nods*\n",
      "are you okay awesom-o?\n",
      "AWESOM_O: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jone/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes. awesom-o is fine. please go on.\n",
      "are you still pretending to be a robot?\n",
      "AWESOM_O: shh!  i just need to uh make butters think i'm a robot for a little while longer.\n",
      "how much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
      "AWESOM_O: seventeen. \n",
      "do you play video games?\n",
      "AWESOM_O: the last two weeks we've been too busy to play video games and, look at what we did. there's been drama, action, romance... i mean honestly you guys, do we need video games to play?\n",
      "can you come up with an idea for a movie that will make more than a hundred million box office?\n",
      "AWESOM_O: um... okay. how about this:  adam sandler is like, in love with some girl, but then it turns out that the girl is actually a... golden retriever, or something.\n",
      "who is your best friend?\n",
      "AWESOM_O: you are, jimmy! we've always been best friends. we know everything about each other.\n",
      "what are you talking about?\n",
      "AWESOM_O: really?\n",
      "forget what?\n",
      "AWESOM_O: eh eh, you're right, colonel sanders! you shouldn't give her any more chicken.\n",
      "colonel sanders?\n",
      "AWESOM_O: what?! oh, that's right, i forgot to- dammit! uh, okay.  put him on speaker.\n",
      "put who on speaker?\n",
      "AWESOM_O: thank you. the latino culture has been very influential on the arts in america. but you don't have to ask me. you can ask my special guest. miss jennifer lopez.\n",
      "who is jennifer lopez?\n",
      "AWESOM_O: what? oh- awww!  ben affleck's spooge!!\n",
      "who are you talking about?\n",
      "AWESOM_O: you don't understand!\n",
      "are you even a robot?\n",
      "AWESOM_O: i'm not a robot, i'm a human!\n",
      "gibberish\n",
      "AWESOM_O: AWESOM-O does not understand\n",
      "your programming seems off\n",
      "AWESOM_O: nnoh, that sounds pretty sweet to me.\n",
      "how are the coding skills of the one who programmed you?\n",
      "AWESOM_O: weak! \n",
      "is there life after death?\n",
      "AWESOM_O: yeah!\n",
      "what happens?\n",
      "AWESOM_O: they drag you out of here, put you in this big containment facility, where they stick a cold metal pipe up your *** with this clear jelly, and then they shock your *****. \n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print('AWESOM-O: Greetings. I am the AWESOM-O 4000. AWESOM-O is here to answer your questions. Type \"shut down\" to end conversation')\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='shut down'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"AWESOM-O: You are welcome\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"AWESOM-O: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"AWESOM_O: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"AWESOM-O: AWESOM-O will now initiate shut down sequence. Goodbye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flask app application \n",
    "# Initialize the app\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def viz_page():\n",
    "    with open(\"chatbot.html\", 'r') as viz_file:\n",
    "        return viz_file.read()\n",
    "\n",
    "@app.route(\"/gof\", methods=[\"POST\"])\n",
    "def chatbot():\n",
    "    \"\"\"\n",
    "    When A POST request with json data is made to this url,\n",
    "    Read the grid from the json, update and send it back\n",
    "    \"\"\"\n",
    "    flag=1\n",
    "    data = flask.request.json\n",
    "    a = data['text']\n",
    "    print(a)\n",
    "    user_response=a.lower()\n",
    "    if(user_response!='shut down'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=0\n",
    "            b = \"AWESOM-O: You are welcome\"\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                b = \"AWESOM-O: \"+greeting(user_response)\n",
    "            else:\n",
    "                b = \"AWESOM_O: \" +  response(user_response)\n",
    "                #b = response(user_response)\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=0\n",
    "        b = \"AWESOM-O: AWESOM-O will now initiate shut down sequence. Goodbye!\"\n",
    "    \n",
    "    print(b)\n",
    "    print (flask.jsonify({'text': b, 'flag': flag}))\n",
    "    return flask.jsonify({'text': b, 'flag': flag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Mar/2019 17:28:49] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2019 17:28:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [21/Mar/2019 17:28:52] \"\u001b[37mPOST /gof HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "AWESOM-O: hello\n",
      "<Response 36 bytes [200 OK]>\n",
      "sup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jone/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cartman sucks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 17:29:11] \"\u001b[37mPOST /gof HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWESOM_O: that's fine! i'd like playing with myself! i'll play with myself all day long!  what?\n",
      "<Response 116 bytes [200 OK]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 17:29:15] \"\u001b[37mPOST /gof HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWESOM_O: that's fine! i'd like playing with myself! i'll play with myself all day long!  what?\n",
      "<Response 116 bytes [200 OK]>\n",
      "fatass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 17:30:15] \"\u001b[37mPOST /gof HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWESOM_O: yeah. i sure did. i don't think i should record that album now.\n",
      "<Response 94 bytes [200 OK]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2019 17:31:33] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------- RUN WEB APP SERVER ------------#\n",
    "\n",
    "# Start the app server on port 80\n",
    "# (The default website port)\n",
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
